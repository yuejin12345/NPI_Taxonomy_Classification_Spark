{"cells":[{"cell_type":"code","source":["# Load libraries\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\n#from imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\n#from sklearn.decomposition import RandomizedPCA\n#from sklearn.pipeline import make_pipeline\nfrom sklearn.naive_bayes import GaussianNB\nfrom collections import Counter\n#from sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n# global import\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport operator\nimport time\n#from imblearn.over_sampling import RandomOverSampler\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["data = spark.table('npi_tax_data_csv') # spark.sql(\"SELECT * FROM \" + npi_tax_data_csv)\ndataDF = data.toPandas()\ndata10 = dataDF.loc[dataDF['from_tinytax'].isin(['from_tinytax', 'Optometrist', 'Anesthesiology', 'Psychiatry', 'Cardiovascular', 'Gastroenterology', 'Neurology', 'Dermatology','Pulmonary','Nephrology','Podiatrist'])]\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data10, test_size=0.2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["# 5 Build Models\nWe don’t know which algorithms would be good on this problem or what configurations to use. We get an idea from the plots that some of the classes are partially linearly separable in some dimensions, so we are expecting generally good results.\n\nLet’s evaluate 5 different algorithms:\n\nLogistic Regression.\nDecision Tree & Random Forest (RF).\nNaive Bayes.\nSupport Vector Machines (SVM).\nk-Nearest Neighbors (kNN).\nLinear Discriminant Analysis (LDA)\nQuadratic Discriminant Analysis (QDA)\nBoosting.\nClassification and Regression Trees (CART).\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice https://www.cs.princeton.edu/~schapire/talks/picasso-minicourse.pdf\n\nThis is a good mixture of simple linear (LDA), nonlinear (CART, kNN, Logistic) and complex nonlinear methods (SVM, RF). We reset the random number seed before reach run to ensure that the evaluation of each algorithm is performed using exactly the same data splits. It ensures the results are directly comparable.\n\n## One-vs-All SGD for Multi-classification\nThe basic idea is to change multiple classes into two classes, and construct one logistic classifier for each class. We set the value of y (label，from_npi_tax_cd) of one class to 1, and 0 for other classes.\n\n### Firstly test the gradient and loss function\nSet the label of the first class to be one, and 0 for others\n\nhttps://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff https://www.geeksforgeeks.org/multiclass-classification-using-scikit-learn/\n\nhttps://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"],"metadata":{}},{"cell_type":"markdown","source":["### 1) Optometrist vs non-Optometrist\n\nLet's simplify the problem for now and only try to identify one taxonomy: Optometrist. So the problem is simplified to distinguishing between Optometrist and non-Optometrist."],"metadata":{}},{"cell_type":"code","source":["X_train = train.iloc[:,2:]\nprint (X_train.head(3))\ny_train = train.iloc[:,1]\nprint (y_train.head(3))\nX_test = test.iloc[:,2:]\ny_test = test.iloc[:,1]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">         Addiction  Adolescent  ...  Urology  Vascular_Interventional\n1138494          0           0  ...       25                        0\n1151272          0           0  ...      417                        0\n286714           0           0  ...        0                        0\n\n[3 rows x 82 columns]\n1138494         Optometrist\n1151272    Gastroenterology\n286714       Anesthesiology\nName: from_tinytax, dtype: object\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["y_train_Optometrist = (y_train == 'Optometrist')\ny_test_Optometrist = (y_test == 'Optometrist')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state = 42)\nsgd_clf.fit(X_train, y_train_Optometrist)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\nOut[34]: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n       l1_ratio=0.15, learning_rate=&#39;optimal&#39;, loss=&#39;hinge&#39;, max_iter=None,\n       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty=&#39;l2&#39;,\n       power_t=0.5, random_state=42, shuffle=True, tol=None,\n       validation_fraction=0.1, verbose=0, warm_start=False)</div>"]}}],"execution_count":7},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, X_train, y_train_Optometrist, cv = 3, scoring = \"accuracy\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\nOut[35]: array([0.94698002, 0.95784056, 0.9617386 ])</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Confusion Matrix:"],"metadata":{}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_predict\ny_test_pred = cross_val_predict(sgd_clf, X_test, y_test_Optometrist, cv = 3)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test_Optometrist, y_test_pred)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\nOut[44]: array([[27659,  3727],\n       [  711,  7539]])</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["Precision and Recall"],"metadata":{}},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score\nprecision_score(y_test_Optometrist, y_test_pred)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[45]: 0.669181608379194</div>"]}}],"execution_count":12},{"cell_type":"code","source":["recall_score(y_test_Optometrist, y_test_pred)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[46]: 0.9138181818181819</div>"]}}],"execution_count":13},{"cell_type":"code","source":["from sklearn.metrics import f1_score\nf1_score(y_test_Optometrist, y_test_pred)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[47]: 0.772596843615495</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["## Multi-class Classification\n### OvO with SGDClassifier:"],"metadata":{}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\ncross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\nOut[52]: array([0.78736448, 0.76098927, 0.77921808])</div>"]}}],"execution_count":16},{"cell_type":"code","source":["sgd_clf.fit(X_train, y_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\nOut[54]: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n       l1_ratio=0.15, learning_rate=&#39;optimal&#39;, loss=&#39;hinge&#39;, max_iter=None,\n       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty=&#39;l2&#39;,\n       power_t=0.5, random_state=42, shuffle=True, tol=None,\n       validation_fraction=0.1, verbose=0, warm_start=False)</div>"]}}],"execution_count":17},{"cell_type":"code","source":["y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\nconf_mx = confusion_matrix(y_train, y_train_pred)\nprint (conf_mx)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n[[22871  1088   247  3272   261   488   244   152  1250   349]\n [  318 11316   165   999  1021   460   109   156  2518   332]\n [  437   140  8365   225    92   122   202   174   420    24]\n [ 2356   225   231  7724   238   177    34    31   937    88]\n [  106   454    25   155  7249    53    30    33   418    86]\n [  605   959   252   450   176  7141   114   182  1762   239]\n [ 1090   570   901   271   175   301 27709   513  1422    85]\n [  718   657   344   233   188   202   285  3936  1349    33]\n [ 1219   813   242   249   239   655   345   378 13790   143]\n [  156   928    51   469   383   360    43    55  1387  5308]]\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["plt.matshow(conf_mx, cmap=plt.cm.gray)\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["y_test_pred = cross_val_predict(sgd_clf, X_test, y_test, cv=3)\nconf_mx_test = confusion_matrix(y_test, y_test_pred)\nprint (conf_mx_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n[[6241  223   81  284   55  243   61   56   36  349]\n [  85 2524   63   12   82  567   15   54   33  891]\n [ 105   30 2068   10    4   77   60   47    9   78]\n [ 858  111   88 1287   41  254   26   10   31  289]\n [  28  123    9    2 1770   53   10   10    7  157]\n [ 190  184   75   10   21 2057   12   42   62  212]\n [ 236  159  230   15   25  237 6838  247   69  194]\n [ 175  165  116    4   28  190   48 1054   60  145]\n [ 323  403  137   17   42  261   51   92 3049  212]\n [  28  223   29    7   44  124    7   11   17 1852]]\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["plt.matshow(conf_mx_test, cmap=plt.cm.gray)\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":22}],"metadata":{"name":"Step20_Models","notebookId":1407527400292374},"nbformat":4,"nbformat_minor":0}
